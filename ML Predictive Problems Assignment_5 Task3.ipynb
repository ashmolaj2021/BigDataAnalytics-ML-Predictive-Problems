{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment 5\n",
    "\n",
    "![image info](https://www.mdpi.com/sensors/sensors-17-01951/article_deploy/html/images/sensors-17-01951-g003.png)\n",
    "\n",
    "\n",
    ">SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and <0.5MB model size\n",
    "(https://arxiv.org/abs/1602.07360)\n",
    "\n",
    "In this assigment you're going to use the pretrained network SqueezeNetv1.2 (~ 5 Mb) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 1 (5 points):\n",
    "\n",
    "go to https://github.com/miaow1988/SqueezeNet_v1.2 and download the 'symbol.json' and '.params' files (there is not a 'synset.txt' file! so don't use these lines, Hint: just comment these lines).\n",
    "\n",
    "* Install MXNet v1.5 (hint: create a new conda environmet with python 3, pip install mxnet==1.5.1) and follow the same steps of the lecture (part: *Using pre-trained models as feature extractors*). Find the flatten output layer and create a feature extractor (hint: It should be a numpy array of 1000 elements).\n",
    "* Download the dogs versus cats *training folder* from https://www.kaggle.com/c/dogs-vs-cats-redux-kernels-edition/data (Remember the number of images is 12500 for each class).\n",
    "* Extract the array of features for different number of images (N: 10, 100, 500, 1000, also 5000 and 12500) and for each value train your favorite binary classifier (only one!!!) using GridSearch to optimize some hyperparameters. Consider to use https://notebooks.csc.fi if you have computational limitations. \n",
    "\n",
    "* Report the accuracy for each value of N and the computational time during the training step.\n",
    "\n",
    "#### Task 2 (5 points):\n",
    "\n",
    "Repeat all previous steps using MobileNet V2 (https://github.com/KeyKy/mobilenet-mxnet). How the two networks compare in terms of accuracy and running time?\n",
    "\n",
    "**WARNING**: At least for N= 5000 and 12500 it can take some time in your computer, depending of your resources. The time can largely increases depending of your chosen classifier.\n",
    "\n",
    "#### Task 3 (5 points):\n",
    "\n",
    "Using the best network. Train a machine learning model able to predic COVID-19 from chest X-Ray images. Use the data from https://www.kaggle.com/praveengovi/coronahack-chest-xraydataset. \n",
    "\n",
    "Present and discuss your best model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK3:\n",
    "\n",
    "#we will use SqueezeNet model for this task as this is identified as better model among TASK1 & TASK2.\n",
    "================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mxnet-cu101==1.5\n",
      "\u001b[33m  WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='files.pythonhosted.org', port=443): Read timed out. (read timeout=15)\")': /packages/2a/19/85b300f607771352ebdd6ddb329efe2839487f6ff0000e0fb4ff1d1c7944/mxnet_cu101-1.5.0-py2.py3-none-manylinux1_x86_64.whl\u001b[0m\n",
      "  Downloading mxnet_cu101-1.5.0-py2.py3-none-manylinux1_x86_64.whl (551.3 MB)\n",
      "\u001b[K     |█████████████████████████▏      | 433.2 MB 34.6 \u001b[K     |████████████████████████████████| 551.3 MB 2.7 kB/s  eta 0:00:0104�██▍      | 438.0 MB 34.6 MB/s eta 0:00:04��███████▌      | 439.7 MB 34.6 MB/s eta 0:00:04█████████████▋      | 441.7 MB 34.6 MB/s eta 0:00:04��███████████████████████▊      | 443.5 MB 34.6 MB/s eta 0:00:04��███████▉      | 444.8 MB 34.6 MB/s eta 0:00:04�███      | 446.3 MB 34.6 MB/s eta 0:00:04��████████      | 448.1 MB 34.6 MB/s eta 0:00:03██████████████▏     | 450.0 MB 34.6 MB/s eta 0:00:03��██▎     | 452.1 MB 34.6 MB/s eta 0:00:03��██▍     | 453.7 MB 34.6 MB/s eta 0:00:03��██▍     | 455.0 MB 34.6 MB/s eta 0:00:03��██▋     | 458.8 MB 35.5 MB/s eta 0:00:03MB/s eta 0:00:03| 462.3 MB 35.5 MB/s eta 0:00:03MB/s eta 0:00:03█████████████████████████     | 466.0 MB 35.5 MB/s eta 0:00:03467.6 MB 35.5 MB/s eta 0:00:03��█████████████▎    | 469.4 MB 35.5 MB/s eta 0:00:03��███████████████████████▍    | 471.2 MB 35.5 MB/s eta 0:00:03███████████████████████████▋    | 474.8 MB 35.5 MB/s eta 0:00:03ta 0:00:03███████▊    | 477.8 MB 35.5 MB/s eta 0:00:03��█████████████▉    | 480.2 MB 35.5 MB/s eta 0:00:03��████████████████████████    | 481.8 MB 35.5 MB/s eta 0:00:02��████    | 483.2 MB 35.5 MB/s eta 0:00:02�███████████▏   | 485.1 MB 35.5 MB/s eta 0:00:02██████████████████▎   | 486.6 MB 28.8 MB/s eta 0:00:03��████████████████████████▎   | 488.2 MB 28.8 MB/s eta 0:00:03�███████████▍   | 490.0 MB 28.8 MB/s eta 0:00:03��████████████████████████▌   | 491.4 MB 28.8 MB/s eta 0:00:03��████████████████████████▊   | 494.7 MB 28.8 MB/s eta 0:00:02��████████████████████████▉   | 496.1 MB 28.8 MB/s eta 0:00:02| 497.4 MB 28.8 MB/s eta 0:00:02��█████████████████████████   | 499.2 MB 28.8 MB/s eta 0:00:02�████████████   | 500.7 MB 28.8 MB/s eta 0:00:023 MB 28.8 MB/s eta 0:00:028.8 MB/s eta 0:00:02ta 0:00:028.8 MB/s eta 0:00:02ta 0:00:02ta 0:00:025.4 MB/s eta 0:00:02�████▉  | 513.7 MB 25.4 MB/s eta 0:00:025.4 MB/s eta 0:00:02ta 0:00:02ta 0:00:02�█▏ | 519.9 MB 25.4 MB/s eta 0:00:02��██████████████▎ | 521.2 MB 25.4 MB/s eta 0:00:02�█▍ | 522.6 MB 25.4 MB/s eta 0:00:02��██████████████▍ | 524.1 MB 25.4 MB/s eta 0:00:02�█▌ | 525.7 MB 25.4 MB/s eta 0:00:02�█████████▋ | 527.1 MB 25.4 MB/s eta 0:00:01████████████████████████████▋ | 528.2 MB 25.4 MB/s eta 0:00:01�█▊ | 529.7 MB 25.4 MB/s eta 0:00:01��██████████████▉ | 531.1 MB 25.4 MB/s eta 0:00:01��███████████████ | 532.7 MB 25.4 MB/s eta 0:00:01MB 25.4 MB/s eta 0:00:01�██ | 535.9 MB 25.4 MB/s eta 0:00:01��███████████▏| 537.5 MB 33.4 MB/s eta 0:00:0101��███████████▍| 540.9 MB 33.4 MB/s eta 0:00:01��███████████▌| 542.9 MB 33.4 MB/s eta 0:00:010101�████████████▉| 547.7 MB 33.4 MB/s eta 0:00:01��████████████| 549.7 MB 33.4 MB/s eta 0:00:0101\n",
      "\u001b[?25hRequirement already satisfied: numpy<2.0.0,>1.16.0 in /opt/conda/lib/python3.7/site-packages (from mxnet-cu101==1.5) (1.18.2)\n",
      "Requirement already satisfied: requests<3,>=2.20.0 in /opt/conda/lib/python3.7/site-packages (from mxnet-cu101==1.5) (2.23.0)\n",
      "Collecting graphviz<0.9.0,>=0.8.1\n",
      "  Downloading graphviz-0.8.4-py2.py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.20.0->mxnet-cu101==1.5) (2.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.20.0->mxnet-cu101==1.5) (2019.11.28)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.20.0->mxnet-cu101==1.5) (1.25.7)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.20.0->mxnet-cu101==1.5) (3.0.4)\n",
      "Installing collected packages: graphviz, mxnet-cu101\n",
      "Successfully installed graphviz-0.8.4 mxnet-cu101-1.5.0\n"
     ]
    }
   ],
   "source": [
    "#! pip install mxnet-cu101==1.5 --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mxnet==1.5.1\n",
      "  Downloading mxnet-1.5.1-py2.py3-none-manylinux1_x86_64.whl (23.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 23.1 MB 2.8 MB/s eta 0:00:01 MB 2.8 MB/s eta 0:00:07B/s eta 0:00:07eta 0:00:06        | 9.4 MB 2.8 MB/s eta 0:00:05█▎                | 11.0 MB 2.8 MB/s eta 0:00:0512.8 MB 2.8 MB/s eta 0:00:04| 14.9 MB 2.8 MB/s eta 0:00:03MB/s eta 0:00:02███████████████████████▎  | 21.2 MB 2.8 MB/s eta 0:00:01��███████████████▉| 23.0 MB 2.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests<3,>=2.20.0 in /opt/conda/lib/python3.7/site-packages (from mxnet==1.5.1) (2.23.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>1.16.0 in /opt/conda/lib/python3.7/site-packages (from mxnet==1.5.1) (1.18.2)\n",
      "Requirement already satisfied: graphviz<0.9.0,>=0.8.1 in /home/jovyan/.local/lib/python3.7/site-packages (from mxnet==1.5.1) (0.8.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.20.0->mxnet==1.5.1) (2019.11.28)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.20.0->mxnet==1.5.1) (2.9)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.20.0->mxnet==1.5.1) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.20.0->mxnet==1.5.1) (1.25.7)\n",
      "Installing collected packages: mxnet\n",
      "Successfully installed mxnet-1.5.1\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (2.23.0)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.7/site-packages (3.2.1)\n",
      "Collecting opencv-python-headless\n",
      "  Downloading opencv_python_headless-4.5.4.58-cp37-cp37m-manylinux2014_x86_64.whl (47.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 47.6 MB 55.5 MB/s eta 0:00:01             | 1.1 MB 3.9 MB/s eta 0:00:128 MB 3.9 MB/s eta 0:00:1212                        | 6.2 MB 3.9 MB/s eta 0:00:11 |█████▋                          | 8.3 MB 3.9 MB/s eta 0:00:11 10.3 MB 3.9 MB/s eta 0:00:10                     | 11.9 MB 3.9 MB/s eta 0:00:103.9 MB/s eta 0:00:09��████▉                     | 16.2 MB 3.9 MB/s eta 0:00:09MB/s eta 0:00:08 MB 3.9 MB/s eta 0:00:0807�██████████▊                | 23.3 MB 3.9 MB/s eta 0:00:07��█▍              | 25.8 MB 3.9 MB/s eta 0:00:06��██████████████▋             | 27.8 MB 3.9 MB/s eta 0:00:06MB/s eta 0:00:05███████████████▍          | 31.8 MB 3.9 MB/s eta 0:00:050:00:01 | 40.0 MB 55.5 MB/s eta 0:00:01�███████████████████████████▏   | 41.9 MB 55.5 MB/s eta 0:00:01�███████████████████████████▌  | 43.9 MB 55.5 MB/s eta 0:00:01 MB 55.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests) (2.9)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests) (1.25.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests) (2019.11.28)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib) (2.8.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: numpy>=1.11 in /opt/conda/lib/python3.7/site-packages (from matplotlib) (1.18.2)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.1->matplotlib) (1.14.0)\n",
      "Installing collected packages: opencv-python-headless\n",
      "Successfully installed opencv-python-headless-4.5.4.58\n"
     ]
    }
   ],
   "source": [
    "#! pip install mxnet==1.5.1 --user\n",
    "#! pip install requests matplotlib opencv-python-headless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model-symbol.json', 'model-0000.params']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mxnet as mx\n",
    "path='https://github.com/miaow1988/SqueezeNet_v1.2/'\n",
    "[mx.test_utils.download(path+'raw/master/model-symbol.json'),\n",
    " mx.test_utils.download(path+'raw/master/model-0000.params')]\n",
    "# mx.test_utils.download(path+'synset.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sym, arg_params, aux_params = mx.model.load_checkpoint(\"./model\", 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = mx.mod.Module(symbol=sym, context=mx.cpu(), label_names=None)\n",
    "mod.bind(for_training=False, data_shapes=[('data', (1,3,224,224))], \n",
    "          label_shapes=mod._label_shapes)\n",
    "mod.set_params(arg_params, aux_params, allow_missing=True)\n",
    "with open('model-symbol.json', 'r') as f:\n",
    "    labels = [l.rstrip() for l in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opendatasets\n",
      "  Downloading opendatasets-0.1.20-py3-none-any.whl (14 kB)\n",
      "Collecting click\n",
      "  Downloading click-8.0.3-py3-none-any.whl (97 kB)\n",
      "\u001b[K     |████████████████████████████████| 97 kB 2.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from opendatasets) (4.43.0)\n",
      "Collecting kaggle\n",
      "  Downloading kaggle-1.5.12.tar.gz (58 kB)\n",
      "\u001b[K     |████████████████████████████████| 58 kB 4.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: importlib-metadata; python_version < \"3.8\" in /opt/conda/lib/python3.7/site-packages (from click->opendatasets) (1.5.0)\n",
      "Requirement already satisfied: six>=1.10 in /opt/conda/lib/python3.7/site-packages (from kaggle->opendatasets) (1.14.0)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.7/site-packages (from kaggle->opendatasets) (2019.11.28)\n",
      "Requirement already satisfied: python-dateutil in /opt/conda/lib/python3.7/site-packages (from kaggle->opendatasets) (2.8.1)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from kaggle->opendatasets) (2.23.0)\n",
      "Collecting python-slugify\n",
      "  Downloading python_slugify-5.0.2-py2.py3-none-any.whl (6.7 kB)\n",
      "Requirement already satisfied: urllib3 in /opt/conda/lib/python3.7/site-packages (from kaggle->opendatasets) (1.25.7)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata; python_version < \"3.8\"->click->opendatasets) (3.1.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->kaggle->opendatasets) (2.9)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->kaggle->opendatasets) (3.0.4)\n",
      "Collecting text-unidecode>=1.3\n",
      "  Downloading text_unidecode-1.3-py2.py3-none-any.whl (78 kB)\n",
      "\u001b[K     |████████████████████████████████| 78 kB 5.3 MB/s  eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: kaggle\n",
      "  Building wheel for kaggle (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for kaggle: filename=kaggle-1.5.12-py3-none-any.whl size=73053 sha256=a4820f78a0bac75966a091a1275aeaa9acee1a316ac81f63b1745f014bd487b3\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/62/d6/58/5853130f941e75b2177d281eb7e44b4a98ed46dd155f556dc5\n",
      "Successfully built kaggle\n",
      "Installing collected packages: click, text-unidecode, python-slugify, kaggle, opendatasets\n",
      "Successfully installed click-8.0.3 kaggle-1.5.12 opendatasets-0.1.20 python-slugify-5.0.2 text-unidecode-1.3\n"
     ]
    }
   ],
   "source": [
    "#! pip install opendatasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please provide your Kaggle credentials to download this dataset. Learn more: http://bit.ly/kaggle-creds\n",
      "Your Kaggle username: abhimolaj\n",
      "Your Kaggle Key: ········\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0.00/1.19G [00:00<?, ?B/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading coronahack-chest-xraydataset.zip to ./coronahack-chest-xraydataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1.19G/1.19G [00:32<00:00, 39.1MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#! pip install opendatasets\n",
    "import opendatasets as od\n",
    "#import zipfile as zf\n",
    "od.download(\"https://www.kaggle.com/praveengovi/coronahack-chest-xraydataset\", force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import os\n",
    "\n",
    "metadata =  pd.read_csv(\"coronahack-chest-xraydataset/Chest_xray_Corona_Metadata.csv\")\n",
    "mypath = join(os.getcwd(),'coronahack-chest-xraydataset/Coronahack-Chest-XRay-Dataset/Coronahack-Chest-XRay-Dataset/train')\n",
    "all_imgs = [join(mypath,f) for f in listdir(mypath)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "covid-19: 58 and no-covid-19: 5852\n"
     ]
    }
   ],
   "source": [
    "covid_imgs = metadata[\"X_ray_image_name\"][metadata[\"Label_2_Virus_category\"] == \"COVID-19\"]\n",
    "no_covid_imgs = metadata[\"X_ray_image_name\"][metadata[\"Label_2_Virus_category\"] != \"COVID-19\"]\n",
    "print(\"covid-19: {} and no-covid-19: {}\".format(len(covid_imgs),len(no_covid_imgs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_imgs = [join(mypath,f) for f in covid_imgs ]\n",
    "no_covid_imgs = [join(mypath,f) for f in no_covid_imgs ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fire9_concat_output',\n",
       " 'dropout0_output',\n",
       " 'conv10_conv_weight',\n",
       " 'conv10_conv_bias',\n",
       " 'conv10_conv_output',\n",
       " 'conv10_relu_output',\n",
       " 'pool10_output',\n",
       " 'flatten0_output',\n",
       " 'softmax_label',\n",
       " 'softmax_output']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list the last 10 layers\n",
    "all_layers = sym.get_internals()\n",
    "all_layers.list_outputs()[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define a simple batch\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "# define a simple data batch\n",
    "from collections import namedtuple\n",
    "Batch = namedtuple('Batch', ['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image(url, show=False):\n",
    "    if url.startswith('http'):\n",
    "        # download and show the image\n",
    "        fname = mx.test_utils.download(url)\n",
    "    else:\n",
    "        fname = url\n",
    "    img = cv2.cvtColor(cv2.imread(fname), cv2.COLOR_BGR2RGB)\n",
    "    if img is None:\n",
    "         return None\n",
    "    if show:\n",
    "         plt.imshow(img)\n",
    "         plt.axis('off')\n",
    "    # convert into format (batch, RGB, width, height)\n",
    "    img = cv2.resize(img, (224, 224))\n",
    "    img = np.swapaxes(img, 0, 2)\n",
    "    img = np.swapaxes(img, 1, 2)\n",
    "    img = img[np.newaxis, :]\n",
    "    return img\n",
    "\n",
    "def predict(url):\n",
    "    img = get_image(url, show=True)\n",
    "    # compute the predict probabilities\n",
    "    mod.forward(Batch([mx.nd.array(img)]))\n",
    "    prob = mod.get_outputs()[0].asnumpy()\n",
    "    # print the top-5\n",
    "    prob = np.squeeze(prob)\n",
    "    a = np.argsort(prob)[::-1]\n",
    "    for i in a[0:5]:\n",
    "        print('probability=%f, class=%s' %(prob[i], labels[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "fe_sym = all_layers['flatten0_output']\n",
    "fe_mod = mx.mod.Module(symbol=fe_sym, context=mx.cpu(), label_names=None)\n",
    "fe_mod.bind(for_training=False, data_shapes=[('data', (1,3,224,224))])\n",
    "fe_mod.set_params(arg_params, aux_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(img):\n",
    "    fe_mod.forward(Batch([mx.nd.array(img)]))\n",
    "    features = fe_mod.get_outputs()[0].asnumpy()\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nmax = 10\n",
    "covid_features = [get_features(get_image(img)).ravel() for img in covid_imgs[:Nmax]]\n",
    "no_covid_features = [get_features(get_image(img)).ravel() for img in no_covid_imgs[:Nmax]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_covid = np.array(Nmax * [1])\n",
    "Y_no_covid = np.array(Nmax * [0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cvd = np.vstack([covid_features,no_covid_features])\n",
    "Y_cvd = np.vstack([Y_covid,Y_no_covid]).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from time import time\n",
    "import warnings\n",
    "\n",
    "param_grid = {'C': [0.001,0.01, 0.1, 1, 3, 5, 7, 10],\n",
    "              'gamma': [0.001, 0.01, 0.1, 1, 3, 5, 7, 10]}\n",
    "grid_search = GridSearchCV(SVC(), param_grid, cv=5)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_cvd, Y_cvd, random_state=42)\n",
    "\n",
    "start = time()\n",
    "grid_search.fit(X_train, y_train)\n",
    "#report(grid_search.cv_results_)\n",
    "stop = time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set score: 0.80\n",
      "gridSearchCV took 0.72 seconds\n",
      "Best parameters: {'C': 1, 'gamma': 0.001}\n",
      "Best cross-validation score: 0.87\n",
      "\n",
      "Best estimator:\n",
      "SVC(C=1, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False)\n"
     ]
    }
   ],
   "source": [
    "print(\"Test set score: {:.2f}\".format(grid_search.score(X_test, y_test)))\n",
    "print(\"gridSearchCV took %.2f seconds\" % ((stop - start)))\n",
    "print(\"Best parameters: {}\".format(grid_search.best_params_))\n",
    "print(\"Best cross-validation score: {:.2f}\\n\".format(grid_search.best_score_))\n",
    "print(\"Best estimator:\\n{}\".format(grid_search.best_estimator_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "As we see above results using SqueezeNet mxnet model and using gridsearchSVC for calculation of results, \n",
    "(i) the test score is 0.80  with processing time 0.60 seconds\n",
    "(ii) the Best cross validation score is 0.87\n",
    "We used Nmax=10\n",
    "\n",
    "When we see the data records, there are 58 covid images against 5852 no-covid images: The results are pretty good. \n",
    "\n",
    "And hence we conclude, this model is performing well for covid dataset used."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
