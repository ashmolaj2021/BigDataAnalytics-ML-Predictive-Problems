{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment 5\n",
    "\n",
    "![image info](https://www.mdpi.com/sensors/sensors-17-01951/article_deploy/html/images/sensors-17-01951-g003.png)\n",
    "\n",
    "\n",
    ">SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and <0.5MB model size\n",
    "(https://arxiv.org/abs/1602.07360)\n",
    "\n",
    "In this assigment you're going to use the pretrained network SqueezeNetv1.2 (~ 5 Mb) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 1 (5 points):\n",
    "\n",
    "go to https://github.com/miaow1988/SqueezeNet_v1.2 and download the 'symbol.json' and '.params' files (there is not a 'synset.txt' file! so don't use these lines, Hint: just comment these lines).\n",
    "\n",
    "* Install MXNet v1.5 (hint: create a new conda environmet with python 3, pip install mxnet==1.5.1) and follow the same steps of the lecture (part: *Using pre-trained models as feature extractors*). Find the flatten output layer and create a feature extractor (hint: It should be a numpy array of 1000 elements).\n",
    "* Download the dogs versus cats *training folder* from https://www.kaggle.com/c/dogs-vs-cats-redux-kernels-edition/data (Remember the number of images is 12500 for each class).\n",
    "* Extract the array of features for different number of images (N: 10, 100, 500, 1000, also 5000 and 12500) and for each value train your favorite binary classifier (only one!!!) using GridSearch to optimize some hyperparameters. Consider to use https://notebooks.csc.fi if you have computational limitations. \n",
    "\n",
    "* Report the accuracy for each value of N and the computational time during the training step.\n",
    "\n",
    "#### Task 2 (5 points):\n",
    "\n",
    "Repeat all previous steps using MobileNet V2 (https://github.com/KeyKy/mobilenet-mxnet). How the two networks compare in terms of accuracy and running time?\n",
    "\n",
    "**WARNING**: At least for N= 5000 and 12500 it can take some time in your computer, depending of your resources. The time can largely increases depending of your chosen classifier.\n",
    "\n",
    "#### Task 3 (5 points):\n",
    "\n",
    "Using the best network. Train a machine learning model able to predic COVID-19 from chest X-Ray images. Use the data from https://www.kaggle.com/praveengovi/coronahack-chest-xraydataset. \n",
    "\n",
    "Present and discuss your best model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install mxnet-cu101==1.5 --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install mxnet==1.5.1 --user\n",
    "#! pip install requests matplotlib opencv-python-headless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mobilenet_v2-symbol.json', 'mobilenet_v2-0000.params']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mxnet as mx1\n",
    "path='https://github.com/KeyKy/mobilenet-mxnet/'\n",
    "[mx1.test_utils.download(path+'raw/master/mobilenet_v2-symbol.json'),\n",
    " mx1.test_utils.download(path+'raw/master/mobilenet_v2-0000.params')]\n",
    "# mx.test_utils.download(path+'synset.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sym1, arg_params1, aux_params1 = mx1.model.load_checkpoint(\"./mobilenet_v2\", 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobile_mod = mx1.mod.Module(symbol=sym1, context=mx1.cpu(), label_names=None)\n",
    "mobile_mod.bind(for_training=False, data_shapes=[('data', (1,3,224,224))], \n",
    "          label_shapes=mobile_mod._label_shapes)\n",
    "mobile_mod.set_params(arg_params1, aux_params1, allow_missing=True)\n",
    "#with open('model-symbol.json', 'r') as f:\n",
    "#    for n in range(10):\n",
    "#        s = f.readline().strip()\n",
    "#        if s: print(s)\n",
    "with open('mobilenet_v2-symbol.json', 'r') as f1:\n",
    "    labels = [l.rstrip() for l in f1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opendatasets\n",
      "  Downloading opendatasets-0.1.20-py3-none-any.whl (14 kB)\n",
      "Collecting click\n",
      "  Downloading click-8.0.3-py3-none-any.whl (97 kB)\n",
      "\u001b[K     |████████████████████████████████| 97 kB 2.7 MB/s eta 0:00:011\n",
      "\u001b[?25hCollecting kaggle\n",
      "  Downloading kaggle-1.5.12.tar.gz (58 kB)\n",
      "\u001b[K     |████████████████████████████████| 58 kB 4.7 MB/s eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from opendatasets) (4.43.0)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /opt/conda/lib/python3.7/site-packages (from click->opendatasets) (1.5.0)\n",
      "Requirement already satisfied: six>=1.10 in /opt/conda/lib/python3.7/site-packages (from kaggle->opendatasets) (1.14.0)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.7/site-packages (from kaggle->opendatasets) (2019.11.28)\n",
      "Requirement already satisfied: python-dateutil in /opt/conda/lib/python3.7/site-packages (from kaggle->opendatasets) (2.8.1)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from kaggle->opendatasets) (2.23.0)\n",
      "Collecting python-slugify\n",
      "  Downloading python_slugify-5.0.2-py2.py3-none-any.whl (6.7 kB)\n",
      "Requirement already satisfied: urllib3 in /opt/conda/lib/python3.7/site-packages (from kaggle->opendatasets) (1.25.7)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata; python_version < \"3.8\"->click->opendatasets) (3.1.0)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->kaggle->opendatasets) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->kaggle->opendatasets) (2.9)\n",
      "Collecting text-unidecode>=1.3\n",
      "  Downloading text_unidecode-1.3-py2.py3-none-any.whl (78 kB)\n",
      "\u001b[K     |████████████████████████████████| 78 kB 4.3 MB/s eta 0:00:011\n",
      "\u001b[?25hBuilding wheels for collected packages: kaggle\n",
      "  Building wheel for kaggle (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for kaggle: filename=kaggle-1.5.12-py3-none-any.whl size=73053 sha256=beb79bfea759d8a194f50282a92b2c2494eee7533c10a38978c0503b8177c4fe\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/62/d6/58/5853130f941e75b2177d281eb7e44b4a98ed46dd155f556dc5\n",
      "Successfully built kaggle\n",
      "Installing collected packages: click, text-unidecode, python-slugify, kaggle, opendatasets\n",
      "Successfully installed click-8.0.3 kaggle-1.5.12 opendatasets-0.1.20 python-slugify-5.0.2 text-unidecode-1.3\n"
     ]
    }
   ],
   "source": [
    "#! pip install opendatasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opendatasets in /opt/conda/lib/python3.7/site-packages (0.1.20)\n",
      "Requirement already satisfied: kaggle in /opt/conda/lib/python3.7/site-packages (from opendatasets) (1.5.12)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from opendatasets) (4.43.0)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from opendatasets) (8.0.3)\n",
      "Requirement already satisfied: six>=1.10 in /opt/conda/lib/python3.7/site-packages (from kaggle->opendatasets) (1.14.0)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.7/site-packages (from kaggle->opendatasets) (2019.11.28)\n",
      "Requirement already satisfied: python-slugify in /opt/conda/lib/python3.7/site-packages (from kaggle->opendatasets) (5.0.2)\n",
      "Requirement already satisfied: python-dateutil in /opt/conda/lib/python3.7/site-packages (from kaggle->opendatasets) (2.8.1)\n",
      "Requirement already satisfied: urllib3 in /opt/conda/lib/python3.7/site-packages (from kaggle->opendatasets) (1.25.7)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from kaggle->opendatasets) (2.23.0)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /opt/conda/lib/python3.7/site-packages (from click->opendatasets) (1.5.0)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in /opt/conda/lib/python3.7/site-packages (from python-slugify->kaggle->opendatasets) (1.3)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->kaggle->opendatasets) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->kaggle->opendatasets) (2.9)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata; python_version < \"3.8\"->click->opendatasets) (3.1.0)\n",
      "Please provide your Kaggle credentials to download this dataset. Learn more: http://bit.ly/kaggle-creds\n",
      "Your Kaggle username: abhimolaj\n",
      "Your Kaggle Key: ········\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1.00M/814M [00:00<02:18, 6.15MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading dogs-vs-cats-redux-kernels-edition.zip to ./dogs-vs-cats-redux-kernels-edition\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 814M/814M [00:20<00:00, 42.6MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting archive ./dogs-vs-cats-redux-kernels-edition/dogs-vs-cats-redux-kernels-edition.zip to ./dogs-vs-cats-redux-kernels-edition\n"
     ]
    }
   ],
   "source": [
    "#! pip install opendatasets\n",
    "#import opendatasets as od\n",
    "#import zipfile as zf\n",
    "#od.download(\"https://www.kaggle.com/c/dogs-vs-cats-redux-kernels-edition/data\", force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#files = zf.ZipFile(\"dogs-vs-cats-redux-kernels-edition/train.zip\", 'r')\n",
    "#files.extractall('images')\n",
    "#files.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import os\n",
    "\n",
    "cats_imgs = [join('images/train',f1) for f1 in listdir('images/train') if f1.startswith('cat')]\n",
    "dogs_imgs = [join('images/train',f1) for f1 in listdir('images/train') if f1.startswith('dog')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cats: 12500 and dogs: 12500\n"
     ]
    }
   ],
   "source": [
    "print(\"cats: {} and dogs: {}\".format(len(cats_imgs),len(dogs_imgs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['conv6_4_bn_moving_var',\n",
       " 'conv6_4_bn_output',\n",
       " 'relu6_4_output',\n",
       " 'pool6_output',\n",
       " 'fc7_weight',\n",
       " 'fc7_bias',\n",
       " 'fc7_conv_output',\n",
       " 'fc7_flatten_output',\n",
       " 'prob_label',\n",
       " 'prob_output']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list the last 10 layers\n",
    "all_layers = sym1.get_internals()\n",
    "all_layers.list_outputs()[-10:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define a simple batch\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "# define a simple data batch\n",
    "from collections import namedtuple\n",
    "Batch = namedtuple('Batch', ['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image(url, show=False):\n",
    "    if url.startswith('http'):\n",
    "        # download and show the image\n",
    "        fname = mx1.test_utils.download(url)\n",
    "    else:\n",
    "        fname = url\n",
    "    img = cv2.cvtColor(cv2.imread(fname), cv2.COLOR_BGR2RGB)\n",
    "    if img is None:\n",
    "         return None\n",
    "    if show:\n",
    "         plt.imshow(img)\n",
    "         plt.axis('off')\n",
    "    # convert into format (batch, RGB, width, height)\n",
    "    img = cv2.resize(img, (224, 224))\n",
    "    img = np.swapaxes(img, 0, 2)\n",
    "    img = np.swapaxes(img, 1, 2)\n",
    "    img = img[np.newaxis, :]\n",
    "    return img\n",
    "\n",
    "def predict(url):\n",
    "    img = get_image(url, show=True)\n",
    "    # compute the predict probabilities\n",
    "    mod.forward(Batch([mx1.nd.array(img)]))\n",
    "    prob = mod.get_outputs()[0].asnumpy()\n",
    "    # print the top-5\n",
    "    prob = np.squeeze(prob)\n",
    "    a = np.argsort(prob)[::-1]\n",
    "    for i in a[0:5]:\n",
    "        print('probability=%f, class=%s' %(prob[i], labels[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "fe_sym = all_layers['fc7_flatten_output']\n",
    "fe_mod = mx1.mod.Module(symbol=fe_sym, context=mx1.cpu(), label_names=None)\n",
    "fe_mod.bind(for_training=False, data_shapes=[('data', (1,3,224,224))])\n",
    "fe_mod.set_params(arg_params1, aux_params1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(img):\n",
    "    fe_mod.forward(Batch([mx1.nd.array(img)]))\n",
    "    features = fe_mod.get_outputs()[0].asnumpy()\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nmax = 10\n",
    "cats_features = [get_features(get_image(img)).ravel() for img in cats_imgs[:Nmax]]\n",
    "dogs_features = [get_features(get_image(img)).ravel() for img in dogs_imgs[:Nmax]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_cats = np.array(Nmax * [1])\n",
    "Y_dogs = np.array(Nmax * [0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cvd = np.vstack([cats_features,dogs_features])\n",
    "Y_cvd = np.vstack([Y_cats,Y_dogs]).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from time import time\n",
    "import warnings\n",
    "\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 3, 5, 7, 10, 12, 20, 120],\n",
    "              'gamma': [0.001, 0.01, 0.1, 1, 3, 5, 7, 10, 12, 20, 100]}\n",
    "grid_search = GridSearchCV(SVC(), param_grid, cv=5)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_cvd, Y_cvd, random_state=0)\n",
    "\n",
    "start = time()\n",
    "grid_search.fit(X_train, y_train)\n",
    "#report(grid_search.cv_results_)\n",
    "stop = time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set score: 0.40\n",
      "gridSearchCV took 1.10 seconds\n",
      "Best parameters: {'C': 0.001, 'gamma': 0.01}\n",
      "Best cross-validation score: 0.53\n",
      "\n",
      "Best estimator:\n",
      "SVC(C=0.001, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False)\n"
     ]
    }
   ],
   "source": [
    "print(\"Test set score: {:.2f}\".format(grid_search.score(X_test, y_test)))\n",
    "print(\"gridSearchCV took %.2f seconds\" % ((stop - start)))\n",
    "print(\"Best parameters: {}\".format(grid_search.best_params_))\n",
    "print(\"Best cross-validation score: {:.2f}\\n\".format(grid_search.best_score_))\n",
    "print(\"Best estimator:\\n{}\".format(grid_search.best_estimator_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see the above results, for Nmax=10, we have used Gridsearch SVC model which took 1.10 seconds time and \n",
    "best cross validation score achieved is 0.53 with hyper parameter values when C is 0.001 and gamma is 0.01. test score is 0.40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set score100: 0.46\n",
      "gridSearchCV100 took 13.40 seconds\n",
      "Best parameters100: {'C': 0.001, 'gamma': 0.001}\n",
      "Best cross-validation score100: 0.51\n",
      "\n",
      "Best estimator100:\n",
      "SVC(C=0.001, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False)\n"
     ]
    }
   ],
   "source": [
    "Nmax100 = 100\n",
    "cats_features100 = [get_features(get_image(img)).ravel() for img in cats_imgs[:Nmax100]]\n",
    "dogs_features100 = [get_features(get_image(img)).ravel() for img in dogs_imgs[:Nmax100]]\n",
    "\n",
    "Y_cats100 = np.array(Nmax100 * [1])\n",
    "Y_dogs100 = np.array(Nmax100 * [0])\n",
    "\n",
    "X_cvd100 = np.vstack([cats_features100,dogs_features100])\n",
    "Y_cvd100 = np.vstack([Y_cats100,Y_dogs100]).ravel()\n",
    "\n",
    "grid_search = GridSearchCV(SVC(), param_grid, cv=5)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_cvd100, Y_cvd100, random_state=0)\n",
    "\n",
    "start = time()\n",
    "grid_search.fit(X_train, y_train)\n",
    "stop = time()\n",
    "\n",
    "print(\"Test set score100: {:.2f}\".format(grid_search.score(X_test, y_test)))\n",
    "print(\"gridSearchCV100 took %.2f seconds\" % ((stop - start)))\n",
    "print(\"Best parameters100: {}\".format(grid_search.best_params_))\n",
    "print(\"Best cross-validation score100: {:.2f}\\n\".format(grid_search.best_score_))\n",
    "print(\"Best estimator100:\\n{}\".format(grid_search.best_estimator_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see the above results, for Nmax=100, we have used Gridsearch SVC model which took 13.40 seconds time and \n",
    "best cross validation score achieved is 0.51 with hyper parameter values when C is 0.001 and gamma is 0.001. test score is 0.46"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set score500: 0.48\n",
      "gridSearchCV500 took 313.06 seconds\n",
      "Best parameters500: {'C': 0.001, 'gamma': 0.001}\n",
      "Best cross-validation score500: 0.51\n",
      "\n",
      "Best estimator500:\n",
      "SVC(C=0.001, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False)\n"
     ]
    }
   ],
   "source": [
    "Nmax500 = 500\n",
    "cats_features500 = [get_features(get_image(img)).ravel() for img in cats_imgs[:Nmax500]]\n",
    "dogs_features500 = [get_features(get_image(img)).ravel() for img in dogs_imgs[:Nmax500]]\n",
    "\n",
    "Y_cats500 = np.array(Nmax500 * [1])\n",
    "Y_dogs500 = np.array(Nmax500 * [0])\n",
    "\n",
    "X_cvd500 = np.vstack([cats_features500,dogs_features500])\n",
    "Y_cvd500 = np.vstack([Y_cats500,Y_dogs500]).ravel()\n",
    "\n",
    "grid_search = GridSearchCV(SVC(), param_grid, cv=5)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_cvd500, Y_cvd500, random_state=0)\n",
    "\n",
    "start = time()\n",
    "grid_search.fit(X_train, y_train)\n",
    "stop = time()\n",
    "\n",
    "print(\"Test set score500: {:.2f}\".format(grid_search.score(X_test, y_test)))\n",
    "print(\"gridSearchCV500 took %.2f seconds\" % ((stop - start)))\n",
    "print(\"Best parameters500: {}\".format(grid_search.best_params_))\n",
    "print(\"Best cross-validation score500: {:.2f}\\n\".format(grid_search.best_score_))\n",
    "print(\"Best estimator500:\\n{}\".format(grid_search.best_estimator_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see the above results, for Nmax=500, we have used Gridsearch SVC model which took 313.06 seconds time and \n",
    "best cross validation score achieved is 0.51 with hyper parameter values when C is 0.001 and gamma is 0.001. test score is 0.48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set score1000: 0.49\n",
      "gridSearchCV1000 took 1233.53 seconds\n",
      "Best parameters1000: {'C': 0.001, 'gamma': 0.001}\n",
      "Best cross-validation score1000: 0.50\n",
      "\n",
      "Best estimator1000:\n",
      "SVC(C=0.001, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False)\n"
     ]
    }
   ],
   "source": [
    "Nmax1000 = 1000\n",
    "cats_features1000 = [get_features(get_image(img)).ravel() for img in cats_imgs[:Nmax1000]]\n",
    "dogs_features1000 = [get_features(get_image(img)).ravel() for img in dogs_imgs[:Nmax1000]]\n",
    "\n",
    "Y_cats1000 = np.array(Nmax1000 * [1])\n",
    "Y_dogs1000 = np.array(Nmax1000 * [0])\n",
    "\n",
    "X_cvd1000 = np.vstack([cats_features1000,dogs_features1000])\n",
    "Y_cvd1000 = np.vstack([Y_cats1000,Y_dogs1000]).ravel()\n",
    "\n",
    "grid_search = GridSearchCV(SVC(), param_grid, cv=5)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_cvd1000, Y_cvd1000, random_state=0)\n",
    "\n",
    "start = time()\n",
    "grid_search.fit(X_train, y_train)\n",
    "stop = time()\n",
    "\n",
    "print(\"Test set score1000: {:.2f}\".format(grid_search.score(X_test, y_test)))\n",
    "print(\"gridSearchCV1000 took %.2f seconds\" % ((stop - start)))\n",
    "print(\"Best parameters1000: {}\".format(grid_search.best_params_))\n",
    "print(\"Best cross-validation score1000: {:.2f}\\n\".format(grid_search.best_score_))\n",
    "print(\"Best estimator1000:\\n{}\".format(grid_search.best_estimator_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see the above results, for Nmax=1000, we have used Gridsearch SVC model which took 1233.53 seconds time and \n",
    "best cross validation score achieved is 0.50 with hyper parameter values when C is 0.001 and gamma is 0.001. test score is 0.49"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see, the improved scores for Mobilenet are achieved when Nmax=1000 as compared to previous values of Nmax.\n",
    "\n",
    "===========================================================================================================\n",
    "###However, when we compare performance of Mobilenet model scores with SqueezeNet w.r.t. time and score, for the dogs vs cat same set of images. \n",
    "We can see there is major difference in scores and time. \n",
    "Squeezenet provides far better scores and processesing time is far less than mobilnet for same Nmax values. \n",
    "\n",
    "Hence, we conclude that SqueeNet is better suitable model for this data as compared to Mobilenet model.\n",
    "================================================================\n",
    "\n",
    "Please see: due to performance issue, the Nmax values 5000 and 12500 respectively are not used and scores are not calculated.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
